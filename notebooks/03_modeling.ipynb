{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50b98a37",
   "metadata": {},
   "source": [
    "# 03. 모델 학습 & 평가\n",
    "\n",
    "여러 분류 모델을 학습하고 교차검증을 통해 성능을 비교한 뒤,\n",
    "최적 모델을 선정하고 테스트 데이터로 최종 평가한다.\n",
    "\n",
    "**핵심 설계 결정:**\n",
    "- 평가 지표: **Recall과 F1** 중심 (퇴사자 누락 비용 > 오경보 비용)\n",
    "- 교차검증: **Stratified 5-Fold** (클래스 불균형 유지)\n",
    "- 불균형 처리: **class_weight='balanced'** 기본 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb19c5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    classification_report, roc_curve, auc, RocCurveDisplay,\n",
    "    precision_recall_curve, PrecisionRecallDisplay\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import joblib\n",
    "\n",
    "from src.data_loader import PROCESSED_DIR\n",
    "from src.evaluation import evaluate_model, plot_confusion_matrix\n",
    "\n",
    "plt.rcParams['font.family'] = 'Apple SD Gothic Neo'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "CV = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4336fd5a",
   "metadata": {},
   "source": [
    "## 3.1 전처리된 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee98226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트리 모델용 (원본 스케일)\n",
    "train = pd.read_csv(PROCESSED_DIR / 'train.csv')\n",
    "test = pd.read_csv(PROCESSED_DIR / 'test.csv')\n",
    "\n",
    "X_train = train.drop(columns=['Attrition'])\n",
    "y_train = train['Attrition']\n",
    "X_test = test.drop(columns=['Attrition'])\n",
    "y_test = test['Attrition']\n",
    "\n",
    "# 선형 모델용 (스케일링)\n",
    "train_s = pd.read_csv(PROCESSED_DIR / 'train_scaled.csv')\n",
    "test_s = pd.read_csv(PROCESSED_DIR / 'test_scaled.csv')\n",
    "\n",
    "X_train_s = train_s.drop(columns=['Attrition'])\n",
    "y_train_s = train_s['Attrition']\n",
    "X_test_s = test_s.drop(columns=['Attrition'])\n",
    "y_test_s = test_s['Attrition']\n",
    "\n",
    "print(f\"학습: {X_train.shape}, 테스트: {X_test.shape}\")\n",
    "print(f\"학습 퇴사율: {y_train.mean():.1%}, 테스트 퇴사율: {y_test.mean():.1%}\")\n",
    "print(f\"피처 수: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb45192",
   "metadata": {},
   "source": [
    "## 3.2 베이스라인 모델\n",
    "\n",
    "모든 예측을 \"재직(0)\"으로 하는 더미 분류기의 성능을 확인한다.\n",
    "이 수치가 **Accuracy의 하한선**이자, 모델이 넘어야 할 최소 기준이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29d20ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 더미 베이스라인: 전부 0(재직)으로 예측\n",
    "y_dummy = np.zeros_like(y_test)\n",
    "dummy_metrics = evaluate_model(y_test, y_dummy)\n",
    "\n",
    "print(\"베이스라인 (전부 재직으로 예측):\")\n",
    "for k, v in dummy_metrics.items():\n",
    "    print(f\"  {k}: {v:.3f}\")\n",
    "print()\n",
    "print(f\"→ Accuracy {dummy_metrics['Accuracy']:.1%}이지만 Recall=0, F1=0\")\n",
    "print(\"→ 퇴사자를 단 한 명도 탐지하지 못함. 이것이 Accuracy만 보면 안 되는 이유.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb49886",
   "metadata": {},
   "source": [
    "## 3.3 다중 모델 교차검증 비교\n",
    "\n",
    "6개 모델을 5-Fold Stratified CV로 비교한다.\n",
    "모든 모델에 `class_weight='balanced'`를 적용하여 소수 클래스(퇴사)에 높은 가중치를 부여한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2433cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': (\n",
    "        LogisticRegression(max_iter=2000, class_weight='balanced', random_state=RANDOM_STATE),\n",
    "        X_train_s, y_train_s  # 스케일링 데이터\n",
    "    ),\n",
    "    'Random Forest': (\n",
    "        RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=RANDOM_STATE),\n",
    "        X_train, y_train\n",
    "    ),\n",
    "    'Gradient Boosting': (\n",
    "        GradientBoostingClassifier(n_estimators=200, random_state=RANDOM_STATE),\n",
    "        X_train, y_train  # GB는 class_weight 미지원, 이후 sample_weight로 처리\n",
    "    ),\n",
    "    'XGBoost': (\n",
    "        XGBClassifier(\n",
    "            n_estimators=200, scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(),\n",
    "            eval_metric='logloss', random_state=RANDOM_STATE, verbosity=0\n",
    "        ),\n",
    "        X_train, y_train\n",
    "    ),\n",
    "    'LightGBM': (\n",
    "        LGBMClassifier(\n",
    "            n_estimators=200, class_weight='balanced',\n",
    "            random_state=RANDOM_STATE, verbosity=-1\n",
    "        ),\n",
    "        X_train, y_train\n",
    "    ),\n",
    "    'SVM (RBF)': (\n",
    "        SVC(kernel='rbf', class_weight='balanced', probability=True, random_state=RANDOM_STATE),\n",
    "        X_train_s, y_train_s  # 스케일링 데이터\n",
    "    ),\n",
    "}\n",
    "\n",
    "scoring = ['accuracy', 'recall', 'precision', 'f1', 'roc_auc']\n",
    "\n",
    "cv_results = {}\n",
    "print(f\"{'모델':<25s} {'Accuracy':>9s} {'Recall':>9s} {'Precision':>9s} {'F1':>9s} {'AUC-ROC':>9s}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for name, (model, X, y) in models.items():\n",
    "    scores = cross_validate(model, X, y, cv=CV, scoring=scoring, n_jobs=-1)\n",
    "    result = {metric: scores[f'test_{metric}'].mean() for metric in scoring}\n",
    "    result_std = {metric: scores[f'test_{metric}'].std() for metric in scoring}\n",
    "    cv_results[name] = {'mean': result, 'std': result_std}\n",
    "\n",
    "    print(f\"{name:<25s} \"\n",
    "          f\"{result['accuracy']:>8.3f}  \"\n",
    "          f\"{result['recall']:>8.3f}  \"\n",
    "          f\"{result['precision']:>8.3f}  \"\n",
    "          f\"{result['f1']:>8.3f}  \"\n",
    "          f\"{result['roc_auc']:>8.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929a5050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV 결과 시각화\n",
    "metrics_to_plot = ['recall', 'f1', 'roc_auc', 'precision']\n",
    "fig, axes = plt.subplots(1, 4, figsize=(22, 6))\n",
    "\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    names = list(cv_results.keys())\n",
    "    means = [cv_results[n]['mean'][metric] for n in names]\n",
    "    stds = [cv_results[n]['std'][metric] for n in names]\n",
    "\n",
    "    colors = ['#E74C3C' if m == max(means) else '#3498DB' for m in means]\n",
    "    bars = axes[i].barh(names, means, xerr=stds, color=colors, alpha=0.8, capsize=3)\n",
    "    axes[i].set_title(metric.upper(), fontsize=13, fontweight='bold')\n",
    "    axes[i].set_xlim(0, 1.05)\n",
    "\n",
    "    for bar, mean in zip(bars, means):\n",
    "        axes[i].text(mean + 0.02, bar.get_y() + bar.get_height()/2,\n",
    "                     f'{mean:.3f}', va='center', fontsize=9)\n",
    "\n",
    "plt.suptitle('모델별 교차검증 성능 비교 (빨강: 최고)', fontsize=15, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/08_model_cv_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ac37e",
   "metadata": {},
   "source": [
    "## 3.4 하이퍼파라미터 튜닝\n",
    "\n",
    "CV 결과에서 상위 2개 모델(LightGBM, XGBoost)에 대해 GridSearchCV로 튜닝한다.\n",
    "- 평가 지표: **F1** (Recall과 Precision의 균형)\n",
    "- 리샘플링: Stratified 5-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca281a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM 튜닝\n",
    "lgbm_params = {\n",
    "    'n_estimators': [200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'num_leaves': [15, 31],\n",
    "    'min_child_samples': [10, 20, 30],\n",
    "}\n",
    "\n",
    "lgbm_grid = GridSearchCV(\n",
    "    LGBMClassifier(class_weight='balanced', random_state=RANDOM_STATE, verbosity=-1),\n",
    "    lgbm_params,\n",
    "    scoring='f1',\n",
    "    cv=CV,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "lgbm_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"LightGBM 최적 파라미터:\")\n",
    "for k, v in lgbm_grid.best_params_.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(f\"  Best F1 (CV): {lgbm_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee64dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost 튜닝\n",
    "xgb_params = {\n",
    "    'n_estimators': [200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "spw = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "xgb_grid = GridSearchCV(\n",
    "    XGBClassifier(scale_pos_weight=spw, eval_metric='logloss',\n",
    "                  random_state=RANDOM_STATE, verbosity=0),\n",
    "    xgb_params,\n",
    "    scoring='f1',\n",
    "    cv=CV,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"XGBoost 최적 파라미터:\")\n",
    "for k, v in xgb_grid.best_params_.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(f\"  Best F1 (CV): {xgb_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf9271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 튜닝 전후 비교\n",
    "print(f\"{'모델':<20s} {'튜닝 전 F1 (CV)':>16s} {'튜닝 후 F1 (CV)':>16s} {'개선':>8s}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "lgbm_before = cv_results['LightGBM']['mean']['f1']\n",
    "xgb_before = cv_results['XGBoost']['mean']['f1']\n",
    "\n",
    "print(f\"{'LightGBM':<20s} {lgbm_before:>15.4f}  {lgbm_grid.best_score_:>15.4f}  {lgbm_grid.best_score_ - lgbm_before:>+7.4f}\")\n",
    "print(f\"{'XGBoost':<20s} {xgb_before:>15.4f}  {xgb_grid.best_score_:>15.4f}  {xgb_grid.best_score_ - xgb_before:>+7.4f}\")\n",
    "\n",
    "# 최종 모델 선택\n",
    "if lgbm_grid.best_score_ >= xgb_grid.best_score_:\n",
    "    best_model = lgbm_grid.best_estimator_\n",
    "    best_name = 'LightGBM (tuned)'\n",
    "else:\n",
    "    best_model = xgb_grid.best_estimator_\n",
    "    best_name = 'XGBoost (tuned)'\n",
    "\n",
    "print(f\"\\n→ 최종 선택: {best_name} (F1={max(lgbm_grid.best_score_, xgb_grid.best_score_):.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60538b0b",
   "metadata": {},
   "source": [
    "## 3.5 최종 모델 — 테스트 데이터 평가\n",
    "\n",
    "**중요**: 테스트 데이터는 이 시점에서 처음 사용된다.\n",
    "교차검증은 학습 데이터 내에서만 수행했으므로, 테스트 성능은 일반화 성능의 추정치이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bdf9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 예측\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 평가 지표\n",
    "test_metrics = evaluate_model(y_test, y_pred, y_prob)\n",
    "\n",
    "print(f\"최종 모델: {best_name}\")\n",
    "print(\"=\" * 50)\n",
    "for k, v in test_metrics.items():\n",
    "    print(f\"  {k:>12s}: {v:.4f}\")\n",
    "\n",
    "print(f\"\\n분류 보고서:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['재직', '퇴사']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526d9bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혼동 행렬\n",
    "fig = plot_confusion_matrix(y_test, y_pred, title=f'{best_name} — 테스트 데이터')\n",
    "plt.savefig('../outputs/figures/09_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 해석\n",
    "tn, fp, fn, tp = __import__('sklearn.metrics', fromlist=['confusion_matrix']).confusion_matrix(y_test, y_pred).ravel()\n",
    "print(f\"TN(재직→재직): {tn}  |  FP(재직→퇴사 오경보): {fp}\")\n",
    "print(f\"FN(퇴사→재직 누락): {fn}  |  TP(퇴사→퇴사 탐지): {tp}\")\n",
    "print(f\"\\n→ {tp}명의 퇴사자를 사전에 탐지, {fn}명은 놓침\")\n",
    "print(f\"→ {fp}명에게 불필요한 개입이 발생하지만 비용은 낮음\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24647ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve & Precision-Recall Curve\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "axes[0].plot(fpr, tpr, color='#E74C3C', lw=2, label=f'{best_name} (AUC={roc_auc:.3f})')\n",
    "axes[0].plot([0, 1], [0, 1], color='gray', linestyle='--', alpha=0.5, label='Random (AUC=0.5)')\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "\n",
    "# Precision-Recall\n",
    "prec, rec, _ = precision_recall_curve(y_test, y_prob)\n",
    "axes[1].plot(rec, prec, color='#3498DB', lw=2, label=f'{best_name}')\n",
    "axes[1].axhline(y=y_test.mean(), color='gray', linestyle='--', alpha=0.5, label=f'Baseline ({y_test.mean():.2f})')\n",
    "axes[1].set_xlabel('Recall')\n",
    "axes[1].set_ylabel('Precision')\n",
    "axes[1].set_title('Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/10_roc_pr_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a05863e",
   "metadata": {},
   "source": [
    "## 3.6 피처 중요도 분석\n",
    "\n",
    "최종 모델이 어떤 변수를 중요하게 사용했는지 확인한다.\n",
    "이 결과는 04_insights 노트북에서 비즈니스 해석에 활용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fd438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 중요도 추출\n",
    "importances = best_model.feature_importances_\n",
    "feat_imp = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# 상위 15개 시각화\n",
    "top_n = 15\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "top = feat_imp.head(top_n).sort_values('importance', ascending=True)\n",
    "colors = ['#E74C3C' if imp > feat_imp['importance'].quantile(0.9) else '#3498DB'\n",
    "          for imp in top['importance']]\n",
    "ax.barh(top['feature'], top['importance'], color=colors)\n",
    "ax.set_title(f'{best_name} — 피처 중요도 Top {top_n}', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/11_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Top 10 피처:\")\n",
    "for i, row in feat_imp.head(10).iterrows():\n",
    "    print(f\"  {row['feature']:30s}  {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f932cd",
   "metadata": {},
   "source": [
    "## 3.7 전체 모델 테스트 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a71ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 모델을 학습 데이터로 fit → 테스트 평가\n",
    "all_test_results = {}\n",
    "\n",
    "for name, (model, X_tr, y_tr) in models.items():\n",
    "    model.fit(X_tr, y_tr)\n",
    "    X_te = X_test_s if name in ['Logistic Regression', 'SVM (RBF)'] else X_test\n",
    "    y_p = model.predict(X_te)\n",
    "    y_pp = model.predict_proba(X_te)[:, 1]\n",
    "    all_test_results[name] = evaluate_model(y_test, y_p, y_pp)\n",
    "\n",
    "# 튜닝된 모델 추가\n",
    "all_test_results[best_name] = test_metrics\n",
    "\n",
    "# 결과 테이블\n",
    "result_df = pd.DataFrame(all_test_results).T\n",
    "result_df = result_df.sort_values('F1', ascending=False)\n",
    "print(\"전체 모델 테스트 성능 비교:\")\n",
    "print(result_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7205982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 성능 시각화\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "metrics_plot = ['Recall', 'F1', 'AUC-ROC', 'Precision']\n",
    "x = np.arange(len(result_df))\n",
    "width = 0.2\n",
    "\n",
    "for i, metric in enumerate(metrics_plot):\n",
    "    bars = ax.bar(x + i * width, result_df[metric], width, label=metric, alpha=0.85)\n",
    "\n",
    "ax.set_xticks(x + width * 1.5)\n",
    "ax.set_xticklabels(result_df.index, rotation=30, ha='right')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.legend()\n",
    "ax.set_title('모델별 테스트 성능 비교', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/12_all_models_test.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d974a6",
   "metadata": {},
   "source": [
    "## 3.8 모델 및 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f78de17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 모델 저장\n",
    "model_path = PROCESSED_DIR.parent.parent / 'outputs' / 'models'\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "joblib.dump(best_model, model_path / 'best_model.joblib')\n",
    "print(f\"모델 저장: outputs/models/best_model.joblib\")\n",
    "\n",
    "# 피처 중요도 저장 (Tableau 대시보드용)\n",
    "feat_imp.to_csv(PROCESSED_DIR / 'feature_importance.csv', index=False)\n",
    "print(f\"피처 중요도 저장: data/processed/feature_importance.csv\")\n",
    "\n",
    "# 예측 확률 저장 (Tableau 대시보드용)\n",
    "full_data = pd.read_csv(PROCESSED_DIR / 'attrition_clean.csv')\n",
    "X_full = full_data.drop(columns=['Attrition'])\n",
    "pred_prob = best_model.predict_proba(X_full)[:, 1]\n",
    "predictions = pd.DataFrame({\n",
    "    'Predict_Prob': pred_prob,\n",
    "    'Risk_Level': pd.cut(pred_prob, bins=[0, 0.3, 0.6, 1.0], labels=['저위험', '중위험', '고위험'])\n",
    "})\n",
    "predictions.to_csv(PROCESSED_DIR / 'predictions.csv', index=False)\n",
    "print(f\"예측 확률 저장: data/processed/predictions.csv\")\n",
    "\n",
    "# 전체 테스트 결과 저장\n",
    "result_df.round(4).to_csv(PROCESSED_DIR / 'model_comparison.csv')\n",
    "print(f\"모델 비교 저장: data/processed/model_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666b8f53",
   "metadata": {},
   "source": [
    "## 3.9 모델링 요약\n",
    "\n",
    "### 최종 모델 선택 근거\n",
    "- 6개 모델을 Stratified 5-Fold CV로 비교\n",
    "- LightGBM과 XGBoost에 대해 GridSearchCV 튜닝\n",
    "- **F1 기준** 최적 모델 선정 (Recall과 Precision의 균형)\n",
    "\n",
    "### 불균형 처리\n",
    "- 모든 모델에 `class_weight='balanced'` 또는 `scale_pos_weight` 적용\n",
    "- Accuracy(84%)가 아닌 **Recall과 F1**로 평가\n",
    "\n",
    "### 다음 단계\n",
    "- 04_insights에서 피처 중요도를 비즈니스 관점으로 해석\n",
    "- 고위험 세그먼트 프로파일링\n",
    "- 실행 가능한 HR 제언 도출"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
